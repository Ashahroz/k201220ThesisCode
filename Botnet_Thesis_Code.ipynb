{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashahroz/k201220ThesisCode/blob/main/Botnet_Thesis_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YsdG-OPRohcf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Bidirectional, TimeDistributed\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "#from pycm import ConfusionMatrix\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import RandomOverSampler  # For class imbalance handling\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6Aid9mwPf8BC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/BotNeTIoT-L01_label_NoDuplicates.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaSgWvjl5e-w",
        "outputId": "b2cd725a-1ef3-44f9-93fe-5fa228a00ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'MI_dir_L0.1_weight', 'MI_dir_L0.1_mean',\n",
            "       'MI_dir_L0.1_variance', 'H_L0.1_weight', 'H_L0.1_mean',\n",
            "       'H_L0.1_variance', 'HH_L0.1_weight', 'HH_L0.1_mean', 'HH_L0.1_std',\n",
            "       'HH_L0.1_magnitude', 'HH_L0.1_radius', 'HH_L0.1_covariance',\n",
            "       'HH_L0.1_pcc', 'HH_jit_L0.1_weight', 'HH_jit_L0.1_mean',\n",
            "       'HH_jit_L0.1_variance', 'HpHp_L0.1_weight', 'HpHp_L0.1_mean',\n",
            "       'HpHp_L0.1_std', 'HpHp_L0.1_magnitude', 'HpHp_L0.1_radius',\n",
            "       'HpHp_L0.1_covariance', 'HpHp_L0.1_pcc', 'label'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zdDcZwz4gYe5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'data' contains your dataset\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = data.drop('label', axis=1)  # Features\n",
        "y = data['label']  # Labels\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ay350nLlQUF9"
      },
      "outputs": [],
      "source": [
        "labels = data['label'].unique().tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPOcvU37PBs9",
        "outputId": "8621782c-99b8-4c16-8059-7cdc3d56543e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.33731e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.31185e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.31527e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.42406e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.41916e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.5101e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9908873618165521\n",
            "Precision: 0.9911463203015685\n",
            "Recall: 0.9908873618165521\n",
            "F1 Score: 0.990942624860462\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create the Ridge Classifier model\n",
        "ridge_clf = RidgeClassifier()\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores = cross_val_score(ridge_clf, X_train, y_train, cv=5)\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "ridge_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = ridge_clf.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCDJKB40RTGz",
        "outputId": "00da4679-4997-41ec-80a2-3c22d65b2b5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.32902e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.35353e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.3843e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.35336e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.33412e-40): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.9910649036371619, Mean Precision: 0.9913172417002366, Mean Recall: 0.9910649036371619, Mean F1 Score: 0.9911184466279643\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Initialize evaluation metrics lists\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Inside your loop for cross-validation\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    # Create and fit the Ridge Classifier model on each fold's training data\n",
        "    ridge_clf = RidgeClassifier()\n",
        "    ridge_clf.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set for this fold\n",
        "    predictions = ridge_clf.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_val_fold, predictions)\n",
        "    precision = precision_score(y_val_fold, predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold, predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold, predictions, average='weighted')\n",
        "\n",
        "    # Append the metrics to the lists\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean evaluation metrics over all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Mean Accuracy: {mean_accuracy}, Mean Precision: {mean_precision}, Mean Recall: {mean_recall}, Mean F1 Score: {mean_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-I8eewEgwIF",
        "outputId": "d45cbe9c-6e39-4f58-fca3-c570723733ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.788294055367832, Mean Precision: 0.6214075823362086, Mean Recall: 0.788294055367832, Mean F1 Score: 0.6949724359532092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize evaluation metrics lists\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Inside your loop for cross-validation\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    # Create and fit the Logistic Regression model on each fold's training data\n",
        "    log_reg = LogisticRegression(max_iter=1000)  # Adjust parameters as needed\n",
        "    log_reg.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set for this fold\n",
        "    predictions = log_reg.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_val_fold, predictions)\n",
        "    precision = precision_score(y_val_fold, predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold, predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold, predictions, average='weighted')\n",
        "\n",
        "    # Append the metrics to the lists\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean evaluation metrics over all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Mean Accuracy: {mean_accuracy}, Mean Precision: {mean_precision}, Mean Recall: {mean_recall}, Mean F1 Score: {mean_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ9NgsjphRd7",
        "outputId": "a2307c5f-d9fd-4882-c859-250e36a3c870"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.9459470468056074, Mean Precision: 0.9638423473269462, Mean Recall: 0.9459470468056074, Mean F1 Score: 0.9493777459196421\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize evaluation metrics lists\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Inside your loop for cross-validation\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    # Create and fit the LinearSVC model on each fold's training data\n",
        "    linear_svc = LinearSVC(max_iter=2500)\n",
        "    linear_svc.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set for this fold\n",
        "    predictions = linear_svc.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_val_fold, predictions)\n",
        "    precision = precision_score(y_val_fold, predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold, predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold, predictions, average='weighted')\n",
        "\n",
        "    # Append the metrics to the lists\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean evaluation metrics over all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Mean Accuracy: {mean_accuracy}, Mean Precision: {mean_precision}, Mean Recall: {mean_recall}, Mean F1 Score: {mean_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLCjVPguc3yG",
        "outputId": "6b8dc182-eb75-4906-d383-def7a7f9a5ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.21234951313705994, Mean Precision: 0.37109214254768264, Mean Recall: 0.21234951313705994, Mean F1 Score: 0.07561010227384077\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize evaluation metrics lists\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Inside your loop for cross-validation\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    # Create and fit the SVC model on each fold's training data\n",
        "    svc = SVC(max_iter=1000)  # You can adjust parameters here\n",
        "    svc.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set for this fold\n",
        "    predictions = svc.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_val_fold, predictions)\n",
        "    precision = precision_score(y_val_fold, predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold, predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold, predictions, average='weighted')\n",
        "\n",
        "    # Append the metrics to the lists\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean evaluation metrics over all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Mean Accuracy: {mean_accuracy}, Mean Precision: {mean_precision}, Mean Recall: {mean_recall}, Mean F1 Score: {mean_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDsb0n9JjkPM",
        "outputId": "d8266df1-375b-491c-c687-27429e4cce9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.7882940554268008, Mean Precision: 0.6214078973998252, Mean Recall: 0.7882940554268008, Mean F1 Score: 0.6949725462441319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize evaluation metrics lists\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Inside your loop for cross-validation\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    # Create and fit the GaussianNB model on each fold's training data\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set for this fold\n",
        "    predictions = gnb.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_val_fold, predictions)\n",
        "    precision = precision_score(y_val_fold, predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold, predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold, predictions, average='weighted')\n",
        "\n",
        "    # Append the metrics to the lists\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean evaluation metrics over all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Mean Accuracy: {mean_accuracy}, Mean Precision: {mean_precision}, Mean Recall: {mean_recall}, Mean F1 Score: {mean_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgCUHn4Ij_wE",
        "outputId": "14a97231-c442-4e49-bac7-ca844d3cae45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.8844392369473347, Mean Precision: 0.9064060557878424, Mean Recall: 0.8844392369473347, Mean F1 Score: 0.8901255796296785\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize evaluation metrics lists\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Inside your loop for cross-validation\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    # Create and fit the BernoulliNB model on each fold's training data\n",
        "    bnb = BernoulliNB()\n",
        "    bnb.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set for this fold\n",
        "    predictions = bnb.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_val_fold, predictions)\n",
        "    precision = precision_score(y_val_fold, predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold, predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold, predictions, average='weighted')\n",
        "\n",
        "    # Append the metrics to the lists\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean evaluation metrics over all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Mean Accuracy: {mean_accuracy}, Mean Precision: {mean_precision}, Mean Recall: {mean_recall}, Mean F1 Score: {mean_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8X0sIKGkXKT",
        "outputId": "551577d2-db43-4784-a5be-4fa04449a237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.9563513436457611, Mean Precision: 0.9569616722716919, Mean Recall: 0.9563513436457611, Mean F1 Score: 0.9565767867576952\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize evaluation metrics lists\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# Inside your loop for cross-validation\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    # Create and fit the SGDClassifier model on each fold's training data\n",
        "    sgd_clf = SGDClassifier()\n",
        "    sgd_clf.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set for this fold\n",
        "    predictions = sgd_clf.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_val_fold, predictions)\n",
        "    precision = precision_score(y_val_fold, predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold, predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold, predictions, average='weighted')\n",
        "\n",
        "    # Append the metrics to the lists\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate mean evaluation metrics over all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "mean_precision = np.mean(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Mean Accuracy: {mean_accuracy}, Mean Precision: {mean_precision}, Mean Recall: {mean_recall}, Mean F1 Score: {mean_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AyuQXBbOzRNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIq-qsBVza2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tg5ITWCcza6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xP887L0dza-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'data' contains your dataset\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = data1.drop('label', axis=1)  # Features\n",
        "y = data1['label']  # Labels\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "R3GE9nYTzRTY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hj0DS3Aken7",
        "outputId": "67885b56-db19-49e4-d3c5-3323f8399017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "Cross-validation scores: [1.         0.99991667 1.         1.         1.        ]\n",
            "Mean cross-validation score: 0.9999833333333333\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Create the RandomForestClassifier model\n",
        "rf_clf = RandomForestClassifier()\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores = cross_val_score(rf_clf, X_train, y_train, cv=5)\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = rf_clf.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define the parameter distributions\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': [None] + list(randint(3, 20).rvs(5)),\n",
        "    'min_samples_split': randint(2, 11),\n",
        "    'min_samples_leaf': randint(1, 5)\n",
        "}\n",
        "\n",
        "# Instantiate RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(RandomForestClassifier(), param_dist, cv=5, scoring='accuracy', n_iter=20)\n",
        "\n",
        "# Fit the randomized search to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# Use the best model\n",
        "best_rf_clf = random_search.best_estimator_\n",
        "# Evaluate the best model\n",
        "best_rf_clf.fit(X_train, y_train)\n",
        "predictions = best_rf_clf.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7Z6Ylb1FgsZ",
        "outputId": "920a5061-ad1b-428e-d3a1-4e8e1aae802d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 82}\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=0.95)  # Retain 95% variance\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Re-fit the model on reduced feature set\n",
        "best_rf_clf.fit(X_train_pca, y_train)\n",
        "predictions = best_rf_clf.predict(X_test_pca)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n4N9ny3Ia9A",
        "outputId": "7709716a-dd7f-436b-96dc-41560b3fc26e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.997625\n",
            "Precision: 0.9976279730989972\n",
            "Recall: 0.997625\n",
            "F1 Score: 0.9976249894533772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Initialize the ExtraTreesClassifier\n",
        "extra_trees_clf = ExtraTreesClassifier()\n",
        "\n",
        "# Perform 5-fold cross-validation on the reduced feature set\n",
        "cv_scores = cross_val_score(extra_trees_clf, X_train_pca, y_train, cv=5)\n",
        "\n",
        "# Fit the ExtraTreesClassifier on the entire training data\n",
        "extra_trees_clf.fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = extra_trees_clf.predict(X_test_pca)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RDPvo55I3Ho",
        "outputId": "f930dd8c-4794-4e2f-ed09-9f9ca0e17676"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.99585\n",
            "Precision: 0.9958512853128226\n",
            "Recall: 0.99585\n",
            "F1 Score: 0.9958500053120136\n",
            "Cross-validation scores: [0.99625    0.99541667 0.99633333 0.99541667 0.9955    ]\n",
            "Mean cross-validation score: 0.9957833333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Initialize the DecisionTreeClassifier\n",
        "decision_tree_clf = DecisionTreeClassifier()\n",
        "\n",
        "# Perform 5-fold cross-validation on the reduced feature set\n",
        "cv_scores = cross_val_score(decision_tree_clf, X_train_pca, y_train, cv=5)\n",
        "\n",
        "# Fit the DecisionTreeClassifier on the entire training data\n",
        "decision_tree_clf.fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = decision_tree_clf.predict(X_test_pca)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVASOFpjJJD-",
        "outputId": "6bb94abb-ce88-41ac-d118-8d65dad97db9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.995775\n",
            "Precision: 0.9957763664792063\n",
            "Recall: 0.995775\n",
            "F1 Score: 0.995775005489873\n",
            "Cross-validation scores: [0.99633333 0.99525    0.99608333 0.99541667 0.99541667]\n",
            "Mean cross-validation score: 0.9956999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IulddNiJlD78",
        "outputId": "38f443d9-4e12-4c8b-90b7-18aac478b3d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.21882591718780586\n",
            "Precision: 0.6957033040071259\n",
            "Recall: 0.21882591718780586\n",
            "F1 Score: 0.09220918668190645\n",
            "Cross-validation scores: [0.21884412 0.21887159 0.21861746 0.21923905 0.21927415]\n",
            "Mean cross-validation score: 0.2189692737528862\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Create the NearestCentroid model\n",
        "nearest_centroid_clf = NearestCentroid()\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores = cross_val_score(nearest_centroid_clf, X_train, y_train, cv=5)\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "nearest_centroid_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = nearest_centroid_clf.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPdHWqsylHGL",
        "outputId": "80cea0d8-36fd-4800-8463-5168fd177d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9898972832078134\n",
            "Precision: 0.9902291977620967\n",
            "Recall: 0.9898972832078134\n",
            "F1 Score: 0.9899669928875353\n",
            "Cross-validation scores: [0.99020567 0.99025719 0.9900477  0.99001679 0.99004423]\n",
            "Mean cross-validation score: 0.9901143175355063\n"
          ]
        }
      ],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Create the LinearDiscriminantAnalysis model\n",
        "lda_clf = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Perform cross-validation with 5 folds\n",
        "cv_scores = cross_val_score(lda_clf, X_train, y_train, cv=5)\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "lda_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = lda_clf.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(f\"Mean cross-validation score: {np.mean(cv_scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBQCqjy8ohLY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wJ5pibjcnfQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE_spyqZcnik"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Kb7vvMLdPvF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4HUNIRndPyT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP5x902TdP1h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSe9OfKhdP5U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "data = pd.read_csv('/content/drive/MyDrive/BotNeTIoT-L01_label_NoDuplicates.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj55Q8u2cnly",
        "outputId": "718aaefa-7477-4593-9a96-a4f9cb96be3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in data: 2426574\n",
            "(100000, 25)\n"
          ]
        }
      ],
      "source": [
        "# Now both datasets should have the same number of samples\n",
        "print(\"Number of samples in data:\", data.shape[0])\n",
        "\n",
        "# Select a subset of the data\n",
        "dataArr = data[:50000]\n",
        "dataArr2 = data[-50000:]\n",
        "\n",
        "data1 = pd.concat([dataArr, dataArr2])\n",
        "\n",
        "# Print the shapes of the data and labels\n",
        "print(data1.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwq8nNlajUgT"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlgzz_9oeHTh",
        "outputId": "08da59bc-f178-42ed-b189-0fd195500b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 1s 1ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "Average Accuracy: 0.6965, Average Precision: 0.699849379631919, Average Recall: 0.99304, Average F1 Score: 0.7964970971327233\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Building a simple feedforward neural network model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E8XeiOa0fhGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNqfHGNhcno_",
        "outputId": "91a17bc6-a225-4288-e7c9-2fa275fea3ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 1s 1ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 1s 1ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 1s 1ms/step\n",
            "Average Accuracy: 0.69659, Average Precision: 0.6997031884234053, Average Recall: 0.993338370039654, Average F1 Score: 0.7966095819179592\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Building a simple feedforward neural network model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXkqvUM3ohWe"
      },
      "outputs": [],
      "source": [
        "# Assuming X is your DataFrame\n",
        "X = X.values.astype(np.float32)  # Convert DataFrame to numpy array\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)  # Reshape for LSTM input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulqIruAq34hM",
        "outputId": "320709a4-4398-4576-c1a6-321adc4a6b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "Average Accuracy: 0.89336, Average Precision: 0.8992259732915262, Average Recall: 0.9876045650171072, Average F1 Score: 0.9267459499484275\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Building a simple feedforward neural network model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjsDkRi-5Gt1",
        "outputId": "c701e44a-c4a0-4607-9605-b15807696c0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 3s 3ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "Average Accuracy: 0.9923400000000001, Average Precision: 0.9998173203057767, Average Recall: 0.9848516017082817, Average F1 Score: 0.9922768845221095\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Reshape the input data for LSTM\n",
        "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "    X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "    # Building a stacked LSTM neural network model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=(1, X_train.shape[2]), return_sequences=True))\n",
        "    model.add(LSTM(32, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E31wjbb5Gw9",
        "outputId": "ad3377d4-9fec-4661-d6b9-84b576b37e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 3ms/step\n",
            "625/625 [==============================] - 3s 3ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 3ms/step\n",
            "Average Accuracy: 0.9913000000000001, Average Precision: 0.9998168605247774, Average Recall: 0.9827740668487358, Average F1 Score: 0.9912214415544357\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Reshape the input data for LSTM\n",
        "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "    X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "    # Building a Vanilla LSTM neural network model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=(1, X_train.shape[2])))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjm856P35G0H",
        "outputId": "067abbbb-fdfb-4818-fb04-2093b75e0938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 2s 3ms/step\n",
            "625/625 [==============================] - 2s 3ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "Average Accuracy: 0.99207, Average Precision: 0.9998172770959943, Average Recall: 0.9843157155880871, Average F1 Score: 0.9920045662676168\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Reshape the input data for GRU\n",
        "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "    X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "    # Building a GRU model\n",
        "    model = Sequential()\n",
        "    model.add(GRU(64, input_shape=(1, X_train.shape[2])))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqtNbQsKMZPF",
        "outputId": "ac913eed-1a26-4c3c-c70e-c94e98b11267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 3ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "Average Accuracy: 0.9917199999999999, Average Precision: 0.9998169527929284, Average Recall: 0.9836220367560096, Average F1 Score: 0.9916526319075902\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Reshape the input data for LSTM with peephole connections\n",
        "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "    X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "    # Building an LSTM model with peephole connections\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=(1, X_train.shape[2]), implementation=2))  # Setting implementation=2 for peephole\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2DIJnJLMZS1",
        "outputId": "1446764a-35e4-465b-b46e-b716c9ea7109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 4s 5ms/step\n",
            "625/625 [==============================] - 5s 7ms/step\n",
            "625/625 [==============================] - 5s 7ms/step\n",
            "625/625 [==============================] - 4s 6ms/step\n",
            "625/625 [==============================] - 4s 5ms/step\n",
            "Average Accuracy: 0.39933, Average Precision: 0.45600460304390983, Average Recall: 0.5976744599274016, Average F1 Score: 0.5082761649746497\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, concatenate\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Reshape the input data for LSTM and CNN\n",
        "    X_train_lstm = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))  # LSTM input shape\n",
        "    X_test_lstm = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    X_train_cnn = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))  # CNN input shape\n",
        "    X_test_cnn = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # LSTM branch\n",
        "    lstm_input = Input(shape=(X_train.shape[1], 1))\n",
        "    lstm_layer = LSTM(64)(lstm_input)\n",
        "\n",
        "    # CNN branch\n",
        "    cnn_input = Input(shape=(X_train.shape[1], 1))\n",
        "    conv1d_layer = Conv1D(32, kernel_size=3, activation='relu')(cnn_input)\n",
        "    maxpooling_layer = MaxPooling1D(pool_size=2)(conv1d_layer)\n",
        "    flatten_layer = Flatten()(maxpooling_layer)\n",
        "\n",
        "    # Concatenating LSTM and CNN branches\n",
        "    concatenated = concatenate([lstm_layer, flatten_layer])\n",
        "\n",
        "    # Output layer\n",
        "    output = Dense(1, activation='sigmoid')(concatenated)\n",
        "\n",
        "    # Creating the model\n",
        "    model = Model(inputs=[lstm_input, cnn_input], outputs=output)\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit([X_train_lstm, X_train_cnn], y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict([X_test_lstm, X_test_cnn])\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1l7BSUYMZWD",
        "outputId": "de8a4550-891d-4a87-c3a7-989e83153179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 4s 5ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "Average Accuracy: 0.9916799999999999, Average Precision: 0.9998170153386429, Average Recall: 0.9835333184202911, Average F1 Score: 0.9916076827748987\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Activation, Dot, Concatenate\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Reshape the input data for LSTM\n",
        "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "    X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "    # Attention layer\n",
        "    class AttentionLayer(tf.keras.layers.Layer):\n",
        "        def __init__(self):\n",
        "            super(AttentionLayer, self).__init__()\n",
        "\n",
        "        def build(self, input_shape):\n",
        "            self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n",
        "            self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1), initializer=\"zeros\")\n",
        "            super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "        def call(self, x):\n",
        "            et = tf.squeeze(tf.tanh(tf.matmul(x, self.W) + self.b), axis=-1)\n",
        "            at = tf.nn.softmax(et)\n",
        "            at = tf.expand_dims(at, axis=-1)\n",
        "            output = x * at\n",
        "            return tf.reduce_sum(output, axis=1)\n",
        "\n",
        "        def compute_output_shape(self, input_shape):\n",
        "            return (input_shape[0], input_shape[-1])\n",
        "\n",
        "    # LSTM with Attention layer\n",
        "    inputs = Input(shape=(1, X_train.shape[2]))\n",
        "    lstm = LSTM(64, return_sequences=True)(inputs)\n",
        "    attention = AttentionLayer()(lstm)\n",
        "    output = Dense(1, activation='sigmoid')(attention)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKVHvW4YZGwZ",
        "outputId": "56504bfd-f21e-4009-af5d-b7a8e8a27746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "625/625 [==============================] - 2s 2ms/step\n",
            "Average Accuracy: 0.9929500000000001, Average Precision: 0.9998173606772847, Average Recall: 0.9860769430891037, Average F1 Score: 0.9928995166482171\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Add\n",
        "\n",
        "# Assuming 'data' contains your DataFrame with the columns you provided\n",
        "# Splitting data into features (X) and labels (y)\n",
        "X = data1.drop(columns=['Unnamed: 0', 'label'])  # Excluding 'Unnamed: 0' and 'label' as features\n",
        "y = data1['label']\n",
        "\n",
        "# Initialize KFold with 5 splits\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Reshape the input data for LSTM\n",
        "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "    X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "    # LSTM layers with skip connections\n",
        "    input_layer = Input(shape=(1, X_train.shape[2]))\n",
        "    lstm_1 = LSTM(64, return_sequences=True)(input_layer)\n",
        "    lstm_2 = LSTM(64, return_sequences=True)(lstm_1)\n",
        "\n",
        "    # Skip connection\n",
        "    skip_connection = Add()([lstm_1, lstm_2])\n",
        "\n",
        "    output = Dense(1, activation='sigmoid')(skip_connection)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Training the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "    # Making predictions on test data\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "    y_pred = y_pred.squeeze(axis=-1).reshape(-1)\n",
        "\n",
        "    # Calculating evaluation metrics for this fold\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Calculate average metrics across all folds\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "avg_precision = np.mean(precisions)\n",
        "avg_recall = np.mean(recalls)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}, Average Precision: {avg_precision}, Average Recall: {avg_recall}, Average F1 Score: {avg_f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uGEnMVuQ25E",
        "outputId": "86d6ba76-9e69-40f2-d3a0-cb3baa3c521f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "print(y.unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRqf0HsDaNi_",
        "outputId": "2cb55003-bfcc-4534-dfe4-58c4c33c8a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_test shape: (20000,)\n",
            "y_pred shape: (20000, 1, 1)\n",
            "y_test type: <class 'pandas.core.series.Series'>\n",
            "y_pred type: <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "print(f\"y_pred shape: {y_pred.shape}\")\n",
        "print(f\"y_test type: {type(y_test)}\")\n",
        "print(f\"y_pred type: {type(y_pred)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG-ptm24aNmB"
      },
      "outputs": [],
      "source": [
        "y_pred = y_pred.squeeze(axis=-1).reshape(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSOmSTYvaNpX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKbvlk8E86Wv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "16tRQ8JA4eiwqVBij8oo8PuqpwQNp5H0I",
      "authorship_tag": "ABX9TyMu8H9q/V/EKrBMxMZMlEok",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}